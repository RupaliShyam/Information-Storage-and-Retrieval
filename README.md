# Information-Storage-and-Retrieval

Task 1: Collection Preprocessing

The documents in TRECTEXT and TRECWEB format are read and normalized. The Document number and 
content of each document in a MAP. Each word in the content is tokenized into individual words and stemmed using Porter Stemming algorithm. Then the text is normalized to lowercase and stop words are eliminated.

Task 2: Indexing

The preprocessed collection is indexed using Lucene. It returns a 2-D array, the first dimension is for each token, and the second dimension records the posting list. The posting list records the documents' docids the token appears and corresponding frequencies of the token.
 
Task 3: Retrieval Model

Automatically translate topic statements to queries. For a given set of topic statements, the code translates the topic statement information into a set of queries that can be recognized by your retrieval module, in which each query corresponds to a search topic and consists of query content and query id. Tokenization, normalization and stop-word removing are conducted on each query.
Implementing the Statistical Language Model - The indexing code is used to return documents based on the ranking of the documents generated by your retrieval model. The retrieval model is the query likelihood model with Dirichlet Prior Smoothing. 

Task 4: Relevance Feedback Model

Enhance the retrieval model with pseudo relevance feedback. That is, for a given query, 
(1)	Obtain feedback documents: conduct the initial search using the query likelihood retrieval model with Dirichlet smoothing  and obtain top K documents where K is a parameter set by the system. These K documents are treated as the relevant documents.
(2)	For each query term qi in the query, calculate the probability of the feedback documents generating this term, i.e., P(qi | feedback documents). Here all feedback documents are treated as one big pseudo document;
(3)	Then for each query term qi, the probability of one document D generating it based on relevance feedback is a linear combination of the original probability P(qi | D) and P(qi | feedback documents), where parameter α is used as the coefficient of P(qi | D) and 1-α is used as the coefficient for P(qi | feedback documents);
(4)	The probability of the query generated by the document is all the probabilities of each query term multiplying together;
(5)	Sort top N documents based on the probability generated in step 4.








